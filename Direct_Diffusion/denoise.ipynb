{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import MnistDataset, unet\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revimg(img):\n",
    "    return (img * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = MnistDataset('train', im_path=\"../data/test/images\").__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(im[0], cmap='gray')\n",
    "axs[0].set_title('im')\n",
    "axs[1].imshow(revimg(im[0]),cmap='gray')\n",
    "axs[1].set_title('revimg(im)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the noise scheduler\n",
    "from diffusion import NoiseScheduler\n",
    "\n",
    "\n",
    "scheduler = NoiseScheduler( noise_start=0.00001,\n",
    "                            noise_end=0.02,\n",
    "                            steps=STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random noise from Z ... \n",
    "noise = torch.randn_like(im)\n",
    "\n",
    "t = 400 - 1#noise to the last step\n",
    "\n",
    "# Add noise to images according to timestep\n",
    "noisy_im = scheduler.add_noise(im, noise, t)\n",
    "\n",
    "plt.imshow(noisy_im[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(1)\n",
    "model.load_state_dict(torch.load(os.path.join(\"out\",\n",
    "                                              \"m1.pth\")))\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_im.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it 1 x 1 x 28 x 28\n",
    "xt = noisy_im.unsqueeze(0).to(device)\n",
    "\n",
    "scheduler.to(device)\n",
    "\n",
    "for i in tqdm(reversed(range(STEPS))):\n",
    "    # Get prediction of noise\n",
    "    noise_pred = model(xt, torch.as_tensor(i).unsqueeze(0).to(device))\n",
    "    \n",
    "    # Use scheduler to get x0 and xt-1\n",
    "    xt, _ = scheduler.sample_prev_timestep(xt, noise_pred, torch.as_tensor(i))\n",
    "    \n",
    "        \n",
    "    #if i % 100 == 0:   # Save x0\n",
    "    #    ims = torch.clamp(xt, -1., 1.).detach().cpu()\n",
    "    #    ims = (ims + 1) / 2\n",
    "    #    img = torchvision.transforms.ToPILImage()(ims[0])\n",
    "    #    if not os.path.exists(os.path.join(\"out\", 'denoise')):\n",
    "    #        os.mkdir(os.path.join(\"out\", 'denoise'))\n",
    "    #    img.save(os.path.join(\"out\", 'denoise', 'x0_{}.png'.format(i)))\n",
    "\n",
    "im_out = torch.clamp(xt, -1., 1.).detach().cpu()\n",
    "img = (im_out + 1) / 2\n",
    "img = torchvision.transforms.ToPILImage()(img[0])\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(im[0], cmap='gray')\n",
    "axs[0].set_title('im')\n",
    "axs[1].imshow(img,cmap='gray')\n",
    "axs[1].set_title('denoised')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = torch.randn((1,1,28,28))\n",
    "# for i in tqdm(reversed(range(STEPS))):\n",
    "#     # Get prediction of noise\n",
    "#     noise_pred = model(n, torch.as_tensor(i).unsqueeze(0))\n",
    "#     \n",
    "#     # Use scheduler to get x0 and xt-1\n",
    "#     n, x0_pred = scheduler.sample_prev_timestep(n, noise_pred, torch.as_tensor(i))\n",
    "# \n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# \n",
    "# img = torchvision.transforms.ToPILImage()(n.squeeze(0))\n",
    "# plt.imshow(img,cmap='gray')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
