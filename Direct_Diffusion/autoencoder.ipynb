{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i can define the blocks that i need ...\n",
    "\n",
    "class resnetBlock(nn.Module):\n",
    "    \n",
    "        def __init__(self, in_channels, out_channels, activation = nn.LeakyReLU()):\n",
    "            super().__init__()\n",
    "            self.activation = activation\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3,stride = 1,  padding=1)\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride = 1, padding=1)\n",
    "\n",
    "                    # nn.(8, in_channels if i == 0 else out_channels),\n",
    "            self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = out_channels\n",
    "            \n",
    "            self.res_input_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            input = x\n",
    "            #print(self.bn1)\n",
    "            #print(\"Before bn1:\", x.shape)\n",
    "\n",
    "            x = self.bn1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.conv2(x)\n",
    "            x = x + self.res_input_conv(input)\n",
    "            return x\n",
    "        \n",
    "class selfAttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels, out_channels, headnums, activation = nn.LeakyReLU()):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.norm = nn.GroupNorm(8, out_channels)\n",
    "        self.satt = nn.MultiheadAttention(out_channels, headnums, batch_first=True)\n",
    "        self.inConv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        input = x\n",
    "        self.b, self.c, self.h, self.w = x.shape\n",
    "        #print(\"Before reshape:\", x.shape)\n",
    "        x = x.reshape(self.b, self.c, self.h * self.w) #reshape to linear ... \n",
    "        #print(\"After reshape:\", x.shape)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        #print(\"After norm:\", x.shape)\n",
    "        x = x.transpose(1,2) # to put channels as last dimension ...\n",
    "        x, _ = self.satt(x, x , x)\n",
    "        #print(\"After self att:\", x.shape)\n",
    "        x = x.transpose(1, 2).reshape(self.b, self.c, self.h, self.w) #reshape back to original shape\n",
    "        #print(\"After reshape x:\", x.shape)\n",
    "        #print(\"After reshape in:\", input.shape)\n",
    "\n",
    "        x = input + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now i can define the 3 types of block (downBlock, upBlock, middleBlock)\n",
    "# check reference video for more details ...\n",
    "\n",
    "class downBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, downsample ,num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.down_sample_conv = nn.Conv2d(out_channels, out_channels, 4, 2, 1) if self.downsample else nn.Identity()\n",
    "\n",
    "        self.resnet = nn.ModuleList([\n",
    "            resnetBlock(in_channels if i == 0 else out_channels, out_channels)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.selfatt =nn.ModuleList([\n",
    "            selfAttentionBlock(out_channels, out_channels, 4)\n",
    "            for _ in range(num_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.resnet[i](x) \n",
    "            x = self.selfatt[i](x)\n",
    "        \n",
    "        x = self.down_sample_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class middleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.initialResnet = resnetBlock(in_channels, out_channels)\n",
    "        \n",
    "        self.resnet = nn.ModuleList([\n",
    "            resnetBlock(out_channels, out_channels)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.selfatt = nn.ModuleList([\n",
    "            selfAttentionBlock(out_channels, out_channels, 4)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.initialResnet(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.selfatt[i](x)\n",
    "            x = self.resnet[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class upBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample, num_layers=1,skip_connections = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.upsample = upsample\n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        self.up_sample_conv = nn.ConvTranspose2d(in_channels, in_channels, 4, 2, 1) if self.upsample else nn.Identity()\n",
    "\n",
    "        self.resnet = nn.ModuleList([\n",
    "            resnetBlock(in_channels if i == 0 else out_channels, out_channels)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.selfatt = nn.ModuleList([\n",
    "            selfAttentionBlock(out_channels, out_channels, 4)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x,downblock_out = None):\n",
    "\n",
    "        x = self.up_sample_conv(x)\n",
    "        if self.skip_connections: \n",
    "            x = x + downblock_out\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            \n",
    "            x = self.resnet[i](x)\n",
    "            x = self.selfatt[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet \n",
    "\n",
    "class unet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels,activation = nn.LeakyReLU(), num_layers=1,skip_connections = False):\n",
    "        super().__init__()\n",
    "        self.down_channels = [32,64,128,256] \n",
    "        self.middle_channels = [256,256,128]\n",
    "        self.up_channels = [128,64,32,16]\n",
    "        self.downsample = [True, True, False]\n",
    "        self.upsample = list(reversed(self.downsample))\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        self.input_conv = nn.Conv2d(in_channels, self.down_channels[0], 3, padding=1)\n",
    "\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(self.down_channels ) - 1):\n",
    "            self.down_blocks.append( \n",
    "                downBlock(self.down_channels[i], self.down_channels[i+1], self.downsample[i], num_layers)\n",
    "            )\n",
    "        self.mid_blocks = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(self.middle_channels) - 1):\n",
    "            self.mid_blocks.append(\n",
    "                middleBlock(self.middle_channels[i], self.middle_channels[i+1], num_layers)\n",
    "            )\n",
    "\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(self.up_channels) - 1):\n",
    "            self.up_blocks.append(\n",
    "                upBlock(self.up_channels[i], self.up_channels[i+1], self.upsample[i], num_layers)\n",
    "            )        \n",
    "\n",
    "        # final conversion to same shape as input ...\n",
    "        self.output_norm = nn.GroupNorm(8,self.up_channels[-1])\n",
    "        self.output_conv = nn.Conv2d(self.up_channels[-1], in_channels, 3, padding=1)\n",
    "\n",
    "\n",
    "\n",
    "    # adding c to condition ...\n",
    "    def forward(self, x):\n",
    "        print(\"input shape: \", x.shape)\n",
    "        x = self.input_conv(x)\n",
    "        print(\"input conv shape: \" , x.shape)\n",
    "        downblock_outs = []\n",
    "\n",
    "        for i in range(len(self.down_blocks)):\n",
    "            if(self.skip_connections):\n",
    "                downblock_outs.append(x)\n",
    "            x = self.down_blocks[i](x)\n",
    "            print(\"downblock shape: \" , x.shape)\n",
    "\n",
    "        for i in range(len(self.mid_blocks)):\n",
    "            x = self.mid_blocks[i](x)\n",
    "            print(\"midblock shape: \" , x.shape)\n",
    "        \n",
    "        for i in range(len(self.up_blocks)): \n",
    "            if(self.skip_connections):\n",
    "                dout = downblock_outs.pop()\n",
    "                x = self.up_blocks[i](x, dout)\n",
    "            else:\n",
    "                x = self.up_blocks[i](x)\n",
    "            print(\"upblock shape: \" , x.shape)\n",
    "        \n",
    "        x = self.output_norm(x)\n",
    "        print(\"output norm shape: \" , x.shape)\n",
    "        x = self.activation(x)\n",
    "        print(\"output activation shape: \" , x.shape)\n",
    "        x = self.output_conv(x)\n",
    "        print(\"output conv shape: \" , x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to test my implementation (from the reference video)\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    r\"\"\"\n",
    "    Nothing special here. Just a simple dataset class for mnist images.\n",
    "    Created a dataset class rather using torchvision to allow\n",
    "    replacement with any other image dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, split, im_path, im_ext='png'):\n",
    "        r\"\"\"\n",
    "        Init method for initializing the dataset properties\n",
    "        :param split: train/test to locate the image files\n",
    "        :param im_path: root folder of images\n",
    "        :param im_ext: image extension. assumes all\n",
    "        images would be this type.\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.im_ext = im_ext\n",
    "        self.images, self.labels = self.load_images(im_path)\n",
    "    \n",
    "    def load_images(self, im_path):\n",
    "        r\"\"\"\n",
    "        Gets all images from the path specified\n",
    "        and stacks them all up\n",
    "        :param im_path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert os.path.exists(im_path), \"images path {} does not exist\".format(im_path)\n",
    "        ims = []\n",
    "        labels = []\n",
    "        for d_name in tqdm(os.listdir(im_path)):\n",
    "            for fname in glob.glob(os.path.join(im_path, d_name, '*.{}'.format(self.im_ext))):\n",
    "                ims.append(fname)\n",
    "                labels.append(int(d_name))\n",
    "       #print('Found {} images for split {}'.format(len(ims), self.split))\n",
    "        return ims, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        im = Image.open(self.images[index])\n",
    "        \n",
    "        im_tensor = torchvision.transforms.ToTensor()(im)\n",
    "        # Convert input to -1 to 1 range.\n",
    "        #im_tensor = (2 * im_tensor) - 1\n",
    "        return im_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = MnistDataset('train', im_path=\"../data/train/images\").__getitem__(0)\n",
    "\n",
    "plt.imshow(im[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 96\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using device:', device)\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    \n",
    "    # Create the dataset\n",
    "    mnist = MnistDataset('train', im_path=\"../data/train/images\")\n",
    "    mnist_loader = DataLoader(mnist, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    \n",
    "    model.train()\n",
    "    # Create output directories\n",
    "    if not os.path.exists(\"out\"):\n",
    "        os.mkdir(\"out\")\n",
    "    \n",
    "    # Specify training parameters\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=255).to(device)\n",
    "    mae = nn.L1Loss()\n",
    "    \n",
    "    # Run training\n",
    "    for epoch_idx in range(NUM_EPOCHS):\n",
    "        losses = []\n",
    "        if device.type == 'cuda':\n",
    "             torch.cuda.empty_cache()\n",
    "        lastimg = None\n",
    "        lastReco = None\n",
    "        for image in tqdm(mnist_loader):\n",
    "            optimizer.zero_grad()\n",
    "            image = image.float().to(device)\n",
    "\n",
    "            reconstructed = model(image)\n",
    "\n",
    "            loss = 1 - ssim(image, reconstructed) + mae(image, reconstructed)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lastimg = image\n",
    "            lastReco = reconstructed\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        axs[0].imshow(lastimg[0][0].detach().cpu(), cmap='gray')\n",
    "        axs[0].set_title('image')\n",
    "        axs[1].imshow(lastReco[0][0].detach().cpu(),cmap='gray')\n",
    "        axs[1].set_title('reconstructed')\n",
    "        plt.show()\n",
    "        print('Finished epoch:{} | Loss : {:.4f}'.format(\n",
    "            epoch_idx + 1,\n",
    "            np.mean(losses),\n",
    "        ))\n",
    "        torch.save(model.state_dict(), os.path.join(\"out_vae\",\n",
    "                                                    \"m1.pth\"))\n",
    "    \n",
    "    print('Done Training ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
