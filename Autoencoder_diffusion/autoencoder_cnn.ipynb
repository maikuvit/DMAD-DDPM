{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('pretrained/vgg_face_dag_NEW.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.features[:11]\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "out = encoder(im)\n",
    "\n",
    "out.shape # torch.Size([1, 256, 28, 28]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.latent_space = nn.Sequential( # this is to have a flatten representation of the latent space ...\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "             \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3,stride=2, padding=1,  output_padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.latent_space(x)\n",
    "        x = torch.reshape(x, (x.shape[0], 256, 56, 56))\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze_encoder(self,freeze = True):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "    def get_embeddings(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.latent_space(x)\n",
    "        return x\n",
    "    \n",
    "    def embeddings_to_out(self,x):\n",
    "        x = torch.reshape(x, (x.shape[0], 256, 56, 56)) # 802816 --> [-1, 1, 896 , 896] \n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze_batchNorm(self, Freeze = True):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                module.requires_grad_ = not Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder(encoder).to(device)\n",
    "model.freeze_encoder()\n",
    "res = model(im.to(device))\n",
    "res[0].shape # ok, same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increasingLoss(losses):\n",
    "    if len(losses) < 3:\n",
    "        return False\n",
    "\n",
    "    last_three = losses[-3:]\n",
    "    return last_three[0] < last_three[1] < last_three[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://webhook.site/8d6aa400-5a8a-47fc-9aca-d6d49cfbad1a\"\n",
    "\n",
    "def send_webHook(url, text):\n",
    "    current_time = datetime.datetime.now()\n",
    "    current_time_str = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    response = requests.get(url, data=f\"at time {current_time_str} -> {text}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"OK\")\n",
    "    else:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model,dataset,device):\n",
    "    model.eval()\n",
    "\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1).to(device)\n",
    "    mse = nn.MSELoss().to(device)\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img in (dataset):\n",
    "            img = img.to(device)\n",
    "            out = model(img).to(device)\n",
    "            vloss = 1 - ssim(out, img) + mse(out, img)\n",
    "            running_vloss += vloss\n",
    "    return running_vloss / len(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start the training loop ...\n",
    "\n",
    "def train(model, dataset, eval_set):\n",
    "    \n",
    "    dataset = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    eval_set = DataLoader(eval_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Create output directories\n",
    "    if not os.path.exists(\"out\"):\n",
    "        os.mkdir(\"out\")\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    last_epoch_change = 0\n",
    "    # Specify training parameters\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    # learning rate scheduler to decrease it gradually ...\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1).to(device)\n",
    "    mse = nn.MSELoss().to(device)\n",
    "    \n",
    "    # Run training\n",
    "    for epoch_idx in range(EPOCHS):\n",
    "        \n",
    "        model.train(True)\n",
    "        \n",
    "        losses = []\n",
    "        eval_losses = []\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "             torch.cuda.empty_cache()\n",
    "\n",
    "        lastimg = None\n",
    "        lastReco = None\n",
    "\n",
    "        for image in tqdm(dataset):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            image = image.float().to(device)\n",
    "\n",
    "            reconstructed = model(image).to(device)\n",
    "\n",
    "\n",
    "            loss = 1 - ssim(image, reconstructed) + mse(image, reconstructed) #combining mse and ssim loss\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lastimg = image\n",
    "            lastReco = reconstructed\n",
    "        \n",
    "        # check last three epochs loss, if the optimizer is not converging, decrease the learning rate ...\n",
    "        if (epoch_idx - last_epoch_change > 2) and increasingLoss(losses) and learning_rate > 0.0001:\n",
    "            learning_rate = learning_rate * 0.1\n",
    "            optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "            # learning rate scheduler to decrease it gradually ...\n",
    "            scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "            last_epoch_change = epoch_idx\n",
    "\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        eval_loss = evaluate_epoch(model, eval_set, device)\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        \n",
    "\n",
    "        axs[0].imshow(lastimg[0].detach().cpu().transpose(0, 2).transpose(0, 1).numpy())\n",
    "        axs[0].set_title('image')\n",
    "        axs[1].imshow(lastReco[0].detach().cpu().transpose(0, 2).transpose(0, 1).numpy())\n",
    "        axs[1].set_title('reconstructed')\n",
    "        plt.show()\n",
    "        result = ('Finished epoch:{} | Loss : {:.4f} | Learning Rate: {} | Eval loss: {}'.format(\n",
    "            epoch_idx + 1,\n",
    "            np.mean(losses),\n",
    "            learning_rate,\n",
    "            eval_loss\n",
    "        ))\n",
    "\n",
    "        send_webHook(URL, result)\n",
    "        print(result)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(\"out_ae\",\n",
    "                                                    \"ae_Casia_{}.pth\".format(epoch_idx)))\n",
    "        if early_stopper.early_stop(eval_loss):\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    print('Done Training ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_LIST = \"/data/michele/dataset_files.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasiaDataset(Dataset):\n",
    "    r\"\"\"\n",
    "    Dataset class to load the Bonafide images. \n",
    "    \"\"\"\n",
    "    def __init__(self, im_path):\n",
    "        \n",
    "        self.images = self.load_images(im_path)\n",
    "        \n",
    "    \n",
    "    def load_images(self, im_path):\n",
    "        r\"\"\"\n",
    "        Gets all images from the path specified\n",
    "        and stacks them all up\n",
    "        :param im_path: file with list of absolute paths to images \n",
    "        :return:\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        assert os.path.isfile(im_path), \"images path file {} does not exist\".format(im_path)\n",
    "        \n",
    "        with open(im_path, 'r') as f:\n",
    "            for line in f:\n",
    "                images.append(line.strip())  \n",
    "\n",
    "        images = images[:1000]  \n",
    "\n",
    "        print('Found {} images.'.format(len(images)))\n",
    "        return images\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        im = Image.open(self.images[index])  \n",
    "        im_tensor = torchvision.transforms.ToTensor()(im)\n",
    "        # Convert input to -1 to 1 range.\n",
    "        #im_tensor = (2 * im_tensor) - 1\n",
    "        return im_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CasiaDataset(FILES_LIST)\n",
    "\n",
    "train_size = int(0.8 * len(ds))\n",
    "test_size = len(ds) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_state_dict(torch.load('out_ae/ae_Casia_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    send_webHook(URL, \"Training completed\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    send_webHook(URL, f\"Error during training: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
